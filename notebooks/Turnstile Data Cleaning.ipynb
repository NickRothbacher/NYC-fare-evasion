{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, time\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "import time\n",
    "\n",
    "#this code comes largely from https://github.com/mkduchak/benson-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of weeks we want to pull from the MTA portal\n",
    "\n",
    "def datelist(startdate, num_weeks):\n",
    "    \"\"\"\n",
    "    For a given Saturday, make a list of dates for the n previous Saturdays\n",
    "    \"\"\"\n",
    "    week_list = [startdate + ((timedelta(days=-7))*i) for i in range(num_weeks)]\n",
    "    clean_weeks = [i.strftime('%y%m%d') for i in week_list]\n",
    "    return clean_weeks\n",
    "\n",
    "\n",
    "# Define the last Saturday we're interested in for 2016 and 2017\n",
    "last18 = datetime(2018, 12, 29)\n",
    "last17 = datetime(2017, 12, 30)\n",
    "last16 = datetime(2016, 12, 31)\n",
    "last15 = datetime(2015, 12, 26)\n",
    "\n",
    "# We'll import data for the 14 weeks preceeding July 1st for both 2016 and 2017\n",
    "weeks_to_import = datelist(last16, 52) # + datelist(start16)\n",
    "#weeks_to_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstile_station_table = pd.read_excel('../data/Turnstile/Remote-Booth-Station.xls').rename({'Remote':'UNIT', 'Booth':'C/A', 'Station':'STATION', 'Line Name': 'LINENAME', 'Division':'DIVISION'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 5)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turnstile_station_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadturndata(date):\n",
    "    # Build the filename\n",
    "    strdate = str(date)\n",
    "        \n",
    "    if strdate == \"111217\":\n",
    "        #this week is messed up for some reason\n",
    "        strdate = '111219'\n",
    "        \n",
    "    if strdate == '100501':\n",
    "        #last week is not a full weeek\n",
    "        strdate = '100505'\n",
    "    \n",
    "    filename = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_'+strdate+'.txt'\n",
    "    \n",
    "    if strdate == '120714':\n",
    "        #this week has weird errors so we're skipping those\n",
    "        df = pd.read_csv(filename, skiprows=10)\n",
    "    else:  \n",
    "        # Read in the csv\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "    return df\n",
    "\n",
    "def loadoldturndata(date):\n",
    "    df = loadturndata(date)\n",
    "    newdf = []\n",
    "    newdf_cols = ['C/A','UNIT','SCP', 'DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        #construct a row of the new format for each of the 4 hour periods in the old df\n",
    "        for i in range(0, 8):\n",
    "            newdf.append([row[0], row[1], row[2], row[3+i*5], row[4+i*5], row[5+i*5], row[6+i*5], row[7+i*5]])\n",
    "            \n",
    "    res = pd.DataFrame(data = newdf, columns = newdf_cols).dropna().merge(turnstile_station_table, how = 'left', on= ['UNIT', 'C/A'])\n",
    "    return res\n",
    "\n",
    "def loadturnlist(dates):\n",
    "    \"\"\"\n",
    "    We'll iterarte through the list of weeks to create dataframes using loadturndata and then concat together into one dataframe \n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    x = []\n",
    "    for i in dates:\n",
    "        print('week '+str(i))\n",
    "        if str(i) == '100529':\n",
    "        #this week is missing we'll skip this week\n",
    "            continue\n",
    "        \n",
    "        #before 10/18/2014, the data format was different so we'll have to do some preprocessing\n",
    "        if int(i) < 141018:\n",
    "            df = (loadoldturndata(i))\n",
    "        else:\n",
    "            df = (loadturndata(i))\n",
    "            df = df.rename({df.columns[10]: 'EXITS'}, axis=1)\n",
    "        x.append(df)\n",
    "        print('done')\n",
    "    data = pd.concat(x)\n",
    "    return data\n",
    "\n",
    "def groups_dict(groups):\n",
    "        group_dict = defaultdict(int)\n",
    "        for i in enumerate(list(groups)):\n",
    "            group_dict[i[1]]= i[0]\n",
    "\n",
    "        return group_dict\n",
    "    \n",
    "def find_diff_prev_row(df_series_col):\n",
    "        col_array = np.array(df_series_col)\n",
    "        col_array_shifted = shift(col_array, 1, cval=np.NaN)\n",
    "        col_diff = abs(col_array - col_array_shifted)\n",
    "\n",
    "        return col_diff\n",
    "\n",
    "def find_first_rows_groups(df_series_col):\n",
    "    col_array = np.array(df_series_col)\n",
    "    col_array_shifted = shift(col_array, 1, cval=np.NaN)\n",
    "    first_row_mask = col_array != col_array_shifted\n",
    "\n",
    "    return first_row_mask\n",
    "    \n",
    "def find_outliers(df_series, multiple_IQR):\n",
    "    \"\"\"\n",
    "    For a series of numerical values, remove the zeros and identify the upper outliers \n",
    "    to return a mask for all outliers in series\n",
    "    \"\"\"\n",
    "    non_zeros = df_series.replace(0, None)\n",
    "    \n",
    "    adjusted_IQR = (non_zeros.quantile(.75) - non_zeros.quantile(.25)) * multiple_IQR\n",
    "    outlier_lim = non_zeros.quantile(.75) + adjusted_IQR\n",
    "    print(outlier_lim)\n",
    "    \n",
    "    outliers = [True if x > outlier_lim else False for x in df_series]\n",
    "    \n",
    "    outlier_count = sum(outliers)\n",
    "    all_data_count = len(df_series)\n",
    "    print('{} outliers identified: {} of all data'.format(outlier_count, round(outlier_count/all_data_count,6)))\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "def find_first_rows_groups(df_series_col):\n",
    "    col_array = np.array(df_series_col)\n",
    "    col_array_shifted = shift(col_array, 1, cval=np.NaN)\n",
    "    first_row_mask = col_array != col_array_shifted\n",
    "\n",
    "    return first_row_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "week = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_100505.txt')\n",
    "newdf = []\n",
    "newdf_cols = ['C/A','UNIT','SCP', 'DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "\n",
    "for index, row in week.iterrows():\n",
    "    #construct a row of the new format for each of the 4 hour periods in the old df\n",
    "    for i in range(0, 8):\n",
    "        newdf.append([row[0], row[1], row[2], row[3+i*5], row[4+i*5], row[5+i*5], row[6+i*5], row[7+i*5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = pd.DataFrame(data = newdf, columns = newdf_cols).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ndf) - len(ndf.merge(turnstile_station_table, how='left', on=['C/A', 'UNIT']).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     236685\n",
       "False       322\n",
       "Name: C/A, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf['C/A'].isin(turnstile_station_table['C/A']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Year: 2014\n",
      "saving\n",
      "done\n",
      "creating datetime\n",
      "done\n",
      "adding useful columns\n",
      "done\n",
      "sorting\n",
      "done\n",
      "Null entry diffs 1\n",
      "Null exit diffs 1\n",
      "Clean Data len: 10793646\n",
      "finding differences\n",
      "done\n",
      "cleaning invalid data\n",
      "done\n",
      "All Data Len: 10793646\n",
      "Entries Outliers\n",
      "4667.0\n",
      "4228 outliers identified: 0.000392 of all data\n",
      "\n",
      " Exit Outliers\n",
      "3175.0\n",
      "1788 outliers identified: 0.000166 of all data\n",
      "Excluding Outliers Len: 10787630\n",
      "Keeping 0.999443\n",
      "Null entry diffs 9418\n",
      "Null exit diffs 9418\n",
      "Clean Data len: 10778212\n",
      "We're throwing away 15434 data points - about 0.0014 of the total\n",
      "--- 6.82455716530482 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#before 10/18/2014, the data format was different so we'll have to do something different\n",
    "last14 = datetime(2014, 12, 27)\n",
    "last13 = datetime(2013, 12, 28)\n",
    "last12 = datetime(2012, 12, 29)\n",
    "last11 = datetime(2011, 12, 31)\n",
    "\n",
    "last10 = datetime(2010, 12, 25)  #2010 is the last year for which this data exists and it only goes back to the week of may 05 2010\n",
    "\n",
    "years = [last14]\n",
    "\n",
    "for year in years:\n",
    "    print('Downloading Year: '+str(year.year))\n",
    "    # Note: This takes a long time to run - go treat yourself to a cup of tea!\n",
    "    weeks_to_import = datelist(year, 35)\n",
    "    #raw = loadturnlist(weeks_to_import)\n",
    "    print('saving')\n",
    "    # Pickle the raw data in case things go south in the cleaning process and you need to start over from here\n",
    "    #raw.to_pickle('Turnstile/raw_{}_turnstile_data.pkl'.format(year.year))\n",
    "    print('done')\n",
    "    raw = pd.read_pickle('../data/Turnstile/raw_{}_turnstile_data.pkl'.format(year.year))\n",
    "    \n",
    "    df = raw.rename(columns=lambda x: x.strip().lower())\n",
    "\n",
    "    print('creating datetime')\n",
    "    # Concat date and time and convert to datetime object\n",
    "    df['datetime'] = df['date'] + ' ' + df['time']\n",
    "    \n",
    "    clean = []\n",
    "    for x in df['datetime']:\n",
    "        try:\n",
    "            clean.append(datetime.strptime(x, '%m/%d/%Y %H:%M:%S'))\n",
    "        except:\n",
    "            clean.append(datetime.strptime(x, '%m-%d-%y %H:%M:%S'))\n",
    "            \n",
    "    df['datetime_clean'] = clean\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "    print(\"adding useful columns\")\n",
    "    # Add some helpful date-part columns\n",
    "    df['year'] = [x.year for x in df['datetime_clean']]\n",
    "    \n",
    "    # Create group ID for distinct turnstiles\n",
    "    df['group'] = df['c/a'].astype(str) + \\\n",
    "                    df['unit'].astype(str) + \\\n",
    "                    df['scp'].astype(str) + \\\n",
    "                    df['station'].astype(str)  + \\\n",
    "                    df['linename'].astype(str) + \\\n",
    "                    df['division'].astype(str) + \\\n",
    "                    df['year'].astype(str)\n",
    "\n",
    "    \n",
    "    # Map 'group' string to integer id     \n",
    "    groups = set(df['group'])\n",
    "\n",
    "    \n",
    "    group_id_dict = groups_dict(groups)\n",
    "\n",
    "    df['group_id'] = [group_id_dict[x] for x in df['group']]\n",
    "\n",
    "    # Create station ID for distinct stations\n",
    "    df['station_line'] = df['station'].astype(str) + \\\n",
    "                    df['linename'].astype(str)\n",
    "    \n",
    "    print('done')\n",
    "    print('sorting')\n",
    "    # Sort values by group id and date to find diff in turnstile counts from prev row \n",
    "    #necessary since data is actually a counter that goes up from the installation of the turnstile and is reported every 4 hours\n",
    "    df.sort_values(['group_id','datetime_clean'], inplace=True)\n",
    "    df.reset_index(drop=True)\n",
    "    print('done')\n",
    "    \n",
    "    df['entries'] = pd.to_numeric(df['entries'], errors = 'coerce')\n",
    "    df['exits'] = pd.to_numeric(df['exits'], errors = 'coerce')\n",
    "\n",
    "    #next we'll delete null values from the dataset\n",
    "    print('Null entry diffs', df.entries.isnull().sum())\n",
    "    print('Null exit diffs', df.exits.isnull().sum())\n",
    "    df.dropna(subset = ['entries', 'exits'], how='any', inplace=True)\n",
    "    print('Clean Data len:', len(df))\n",
    "        \n",
    "    print('finding differences')\n",
    "    df['entries_diff'] = find_diff_prev_row(pd.to_numeric(df['entries'], errors = 'coerce'))\n",
    "    df['exit_diff'] = find_diff_prev_row(pd.to_numeric(df['exits'], errors = 'coerce'))\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "    print('cleaning invalid data')\n",
    "    # Identify first rows for each group partition to use as mask when setting invalid values to nan\n",
    "    #first rows can't be used because that data is not able to be difference\n",
    "    df['first_row_group'] = find_first_rows_groups(df['group_id'])\n",
    "\n",
    "    # Make entries_diff and exit_diff nan when first row in group or negative value\n",
    "    df.loc[df['first_row_group'], 'entries_diff'] = None\n",
    "    df.loc[df['entries_diff'] < 0, 'entries_diff'] = None\n",
    "\n",
    "    df.loc[df['first_row_group'], 'exit_diff'] = None\n",
    "    df.loc[df['exit_diff'] < 0, 'exit_diff'] = None\n",
    "    print('done')\n",
    "    \n",
    "    #here we use 20 times the IQR as outliers, this should catch rollovers and other data artifacts\n",
    "    #seems like entries of about 5,000 in a four hour period for one unit at one station is a reasonable upper limit\n",
    "    print('All Data Len:', len(df))\n",
    "    print('Entries Outliers')\n",
    "    df['entries_outlier'] = find_outliers(df['entries_diff'], 20)\n",
    "\n",
    "    #delete these outliers detected here\n",
    "    clean_df = df.loc[(~df['entries_outlier'])].copy()\n",
    "\n",
    "    print('\\n Exit Outliers')\n",
    "    clean_df['exit_outlier'] = find_outliers(clean_df['exit_diff'], 20)\n",
    "\n",
    "\n",
    "    #delete these outliers detected here\n",
    "    clean_df = clean_df.loc[(~clean_df['exit_outlier'])].copy()\n",
    "\n",
    "    print('Excluding Outliers Len:', len(clean_df))\n",
    "\n",
    "    print('Keeping', round(len(clean_df)/len(df), 6))\n",
    "    \n",
    "    # Identify first rows for each group partition to use as mask when setting invalid values to nan\n",
    "    #first rows can't be used because that data is not able to be differenced\n",
    "    df['first_row_group'] = find_first_rows_groups(df['group_id'])\n",
    "\n",
    "    # Make entries_diff and exit_diff nan when first row in group or negative value\n",
    "    df.loc[df['first_row_group'], 'entries_diff'] = None\n",
    "    df.loc[df['entries_diff'] < 0, 'entries_diff'] = None\n",
    "\n",
    "    df.loc[df['first_row_group'], 'exit_diff'] = None\n",
    "    df.loc[df['exit_diff'] < 0, 'exit_diff'] = None\n",
    "    \n",
    "    #next we'll delete null values from the dataset\n",
    "    print('Null entry diffs', clean_df.entries_diff.isnull().sum())\n",
    "    print('Null exit diffs', clean_df.exit_diff.isnull().sum())\n",
    "    clean_df.dropna(subset = ['entries_diff', 'exit_diff'], how='any', inplace=True)\n",
    "    print('Clean Data len:', len(clean_df))\n",
    "    \n",
    "    #report total number of data points deleted\n",
    "    thrown_away = len(df) - len(clean_df)\n",
    "    print(\"We're throwing away {} data points - about {} of the total\".format(thrown_away, round(thrown_away/len(df), 4)))\n",
    "    \n",
    "    #consolidate identitcal datetime columns\n",
    "    clean_df = clean_df.drop(['datetime', 'date', 'time', 'group'], axis=1)\n",
    "    clean_df = clean_df.rename({'datetime_clean':'datetime'}, axis=1)\n",
    "    \n",
    "    #get rid of useless columns\n",
    "    clean_df = clean_df.drop(['first_row_group', 'entries_outlier', 'exit_outlier', 'entries', 'exits'], axis=1)\n",
    "    clean_df = clean_df.rename({'entries_diff':'entries', 'exit_diff':'exits'} , axis=1)\n",
    "    \n",
    "    #Now sum up all the turnstiles at each subway station since thats the granularity we desire\n",
    "    stations = clean_df.groupby(['station_line', 'datetime']).agg({'entries':'sum', 'exits':'sum'}).reset_index()\n",
    "    #add back the other information from the original df\n",
    "    stations_clean = stations.merge(clean_df[['station_line', 'datetime','station', 'linename', 'division', 'year']], how='left', copy=False, on=['station_line', 'datetime']).drop_duplicates(subset=['station_line', 'datetime'])\n",
    "    \n",
    "    stations_clean.to_pickle('../data/Turnstile/cleaned_{}_turnstile_data.pkl'.format(year.year))\n",
    "    \n",
    "    print(\"--- {} minutes ---\" .format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999092106849"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = pd.to_numeric(df['exits'], errors = 'coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162565"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw) - len(raw.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "raw = pd.read_pickle('../data/Turnstile/raw_{}_turnstile_data.pkl'.format(year.year))\n",
    "df = raw.rename(columns=lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat date and time and convert to datetime object\n",
    "df['datetime'] = df['date'] + ' ' + df['time']\n",
    "clean = []\n",
    "for x in df['datetime']:\n",
    "    try:\n",
    "        clean.append(datetime.strptime(x, '%m/%d/%Y %H:%M:%S'))\n",
    "    except:\n",
    "        clean.append(datetime.strptime(x, '%m-%d-%y %H:%M:%S'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime_clean'] = clean\n",
    "df['year'] = [x.year for x in df['datetime_clean']]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c/a</th>\n",
       "      <th>unit</th>\n",
       "      <th>scp</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>desc</th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "      <th>station</th>\n",
       "      <th>linename</th>\n",
       "      <th>division</th>\n",
       "      <th>datetime</th>\n",
       "      <th>datetime_clean</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>12-23-12</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>3923303.0</td>\n",
       "      <td>1.35307e+06</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>456NQR</td>\n",
       "      <td>BMT</td>\n",
       "      <td>12-23-12 11:00:00</td>\n",
       "      <td>2012-12-23 11:00:00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>12-23-12</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>3923497.0</td>\n",
       "      <td>1.35313e+06</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>456NQR</td>\n",
       "      <td>BMT</td>\n",
       "      <td>12-23-12 15:00:00</td>\n",
       "      <td>2012-12-23 15:00:00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>12-23-12</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>3923744.0</td>\n",
       "      <td>1.35317e+06</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>456NQR</td>\n",
       "      <td>BMT</td>\n",
       "      <td>12-23-12 19:00:00</td>\n",
       "      <td>2012-12-23 19:00:00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>12-23-12</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>3923935.0</td>\n",
       "      <td>1.3532e+06</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>456NQR</td>\n",
       "      <td>BMT</td>\n",
       "      <td>12-23-12 23:00:00</td>\n",
       "      <td>2012-12-23 23:00:00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>12-24-12</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>3923955.0</td>\n",
       "      <td>1.3532e+06</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>456NQR</td>\n",
       "      <td>BMT</td>\n",
       "      <td>12-24-12 03:00:00</td>\n",
       "      <td>2012-12-24 03:00:00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c/a  unit       scp      date      time     desc    entries        exits  \\\n",
       "0  A002  R051  02-00-00  12-23-12  11:00:00  REGULAR  3923303.0  1.35307e+06   \n",
       "1  A002  R051  02-00-00  12-23-12  15:00:00  REGULAR  3923497.0  1.35313e+06   \n",
       "2  A002  R051  02-00-00  12-23-12  19:00:00  REGULAR  3923744.0  1.35317e+06   \n",
       "3  A002  R051  02-00-00  12-23-12  23:00:00  REGULAR  3923935.0   1.3532e+06   \n",
       "4  A002  R051  02-00-00  12-24-12  03:00:00  REGULAR  3923955.0   1.3532e+06   \n",
       "\n",
       "         station linename division           datetime      datetime_clean  \\\n",
       "0  LEXINGTON AVE   456NQR      BMT  12-23-12 11:00:00 2012-12-23 11:00:00   \n",
       "1  LEXINGTON AVE   456NQR      BMT  12-23-12 15:00:00 2012-12-23 15:00:00   \n",
       "2  LEXINGTON AVE   456NQR      BMT  12-23-12 19:00:00 2012-12-23 19:00:00   \n",
       "3  LEXINGTON AVE   456NQR      BMT  12-23-12 23:00:00 2012-12-23 23:00:00   \n",
       "4  LEXINGTON AVE   456NQR      BMT  12-24-12 03:00:00 2012-12-24 03:00:00   \n",
       "\n",
       "   year  \n",
       "0  2012  \n",
       "1  2012  \n",
       "2  2012  \n",
       "3  2012  \n",
       "4  2012  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group ID for distinct turnstiles\n",
    "df['group'] = df['c/a'].astype(str) + \\\n",
    "                df['unit'].astype(str) + \\\n",
    "                df['scp'].astype(str) + \\\n",
    "                df['station'].astype(str)  + \\\n",
    "                df['linename'].astype(str) + \\\n",
    "                df['division'].astype(str) + \\\n",
    "                df['year'].astype(str)\n",
    "                \n",
    "# Map 'group' string to integer id     \n",
    "groups = set(df['group'])\n",
    "\n",
    "\n",
    "def groups_dict(groups):\n",
    "    group_dict = defaultdict(int)\n",
    "    for i in enumerate(list(groups)):\n",
    "        group_dict[i[1]]= i[0]\n",
    "\n",
    "    return group_dict\n",
    "\n",
    "group_id_dict = groups_dict(groups)\n",
    "\n",
    "df['group_id'] = [group_id_dict[x] for x in df['group']]\n",
    "\n",
    "# Create station ID for distinct stations\n",
    "df['station_line'] = df['station'].astype(str) + \\\n",
    "                df['linename'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by group id and date to find diff in turnstile counts from prev row \n",
    "#necessary since data is actually a counter that goes up from the installation of the turnstile and is reported every 4 hours\n",
    "df.sort_values(['group_id','datetime_clean'], inplace=True)\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "def find_diff_prev_row(df_series_col):\n",
    "    col_array = np.array(df_series_col)\n",
    "    col_array_shifted = shift(col_array, 1, cval=np.NaN)\n",
    "    col_diff = abs(col_array - col_array_shifted)\n",
    "\n",
    "    return col_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null entry diffs 0\n",
      "Null exit diffs 1\n",
      "Clean Data len: 11014511\n"
     ]
    }
   ],
   "source": [
    "df['entries'] = pd.to_numeric(df['entries'], errors = 'coerce')\n",
    "df['exits'] = pd.to_numeric(df['exits'], errors = 'coerce')\n",
    "\n",
    "#next we'll delete null values from the dataset\n",
    "print('Null entry diffs', df.entries.isnull().sum())\n",
    "print('Null exit diffs', df.exits.isnull().sum())\n",
    "df.dropna(subset = ['entries', 'exits'], how='any', inplace=True)\n",
    "print('Clean Data len:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entries_diff'] = find_diff_prev_row(df['entries'])\n",
    "df['exit_diff'] = find_diff_prev_row(df['exits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify first rows for each group partition to use as mask when setting invalid values to nan\n",
    "#first rows can't be used because that data is not able to be differenced\n",
    "def find_first_rows_groups(df_series_col):\n",
    "    col_array = np.array(df_series_col)\n",
    "    col_array_shifted = shift(col_array, 1, cval=np.NaN)\n",
    "    first_row_mask = col_array != col_array_shifted\n",
    "\n",
    "    return first_row_mask\n",
    "\n",
    "\n",
    "df['first_row_group'] = find_first_rows_groups(df['group_id'])\n",
    "\n",
    "# Make entries_diff and exit_diff nan when first row in group or negative value\n",
    "df.loc[df['first_row_group'], 'entries_diff'] = None\n",
    "df.loc[df['entries_diff'] < 0, 'entries_diff'] = None\n",
    "\n",
    "df.loc[df['first_row_group'], 'exit_diff'] = None\n",
    "df.loc[df['exit_diff'] < 0, 'exit_diff'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "      <th>year</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entries_diff</th>\n",
       "      <th>exit_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.101451e+07</td>\n",
       "      <td>1.101451e+07</td>\n",
       "      <td>1.101451e+07</td>\n",
       "      <td>1.101451e+07</td>\n",
       "      <td>1.100550e+07</td>\n",
       "      <td>1.100550e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.206010e+06</td>\n",
       "      <td>2.629980e+06</td>\n",
       "      <td>2.011997e+03</td>\n",
       "      <td>4.551358e+03</td>\n",
       "      <td>1.207441e+03</td>\n",
       "      <td>1.211696e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.245853e+06</td>\n",
       "      <td>9.025329e+06</td>\n",
       "      <td>5.074288e-02</td>\n",
       "      <td>2.594401e+03</td>\n",
       "      <td>6.007165e+05</td>\n",
       "      <td>6.041444e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.789972e+08</td>\n",
       "      <td>2.011000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.431185e+05</td>\n",
       "      <td>2.087390e+05</td>\n",
       "      <td>2.012000e+03</td>\n",
       "      <td>2.305000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.903791e+06</td>\n",
       "      <td>1.235871e+06</td>\n",
       "      <td>2.012000e+03</td>\n",
       "      <td>4.632000e+03</td>\n",
       "      <td>5.500000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.688051e+06</td>\n",
       "      <td>3.555884e+06</td>\n",
       "      <td>2.012000e+03</td>\n",
       "      <td>6.768000e+03</td>\n",
       "      <td>2.120000e+02</td>\n",
       "      <td>1.510000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.060372e+08</td>\n",
       "      <td>9.276785e+08</td>\n",
       "      <td>2.012000e+03</td>\n",
       "      <td>9.015000e+03</td>\n",
       "      <td>9.024560e+08</td>\n",
       "      <td>9.262858e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            entries         exits          year      group_id  entries_diff  \\\n",
       "count  1.101451e+07  1.101451e+07  1.101451e+07  1.101451e+07  1.100550e+07   \n",
       "mean   3.206010e+06  2.629980e+06  2.011997e+03  4.551358e+03  1.207441e+03   \n",
       "std    7.245853e+06  9.025329e+06  5.074288e-02  2.594401e+03  6.007165e+05   \n",
       "min    0.000000e+00 -8.789972e+08  2.011000e+03  0.000000e+00  0.000000e+00   \n",
       "25%    3.431185e+05  2.087390e+05  2.012000e+03  2.305000e+03  3.000000e+00   \n",
       "50%    1.903791e+06  1.235871e+06  2.012000e+03  4.632000e+03  5.500000e+01   \n",
       "75%    4.688051e+06  3.555884e+06  2.012000e+03  6.768000e+03  2.120000e+02   \n",
       "max    9.060372e+08  9.276785e+08  2.012000e+03  9.015000e+03  9.024560e+08   \n",
       "\n",
       "          exit_diff  \n",
       "count  1.100550e+07  \n",
       "mean   1.211696e+03  \n",
       "std    6.041444e+05  \n",
       "min    0.000000e+00  \n",
       "25%    2.000000e+00  \n",
       "50%    4.000000e+01  \n",
       "75%    1.510000e+02  \n",
       "max    9.262858e+08  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notice that while the majority of data is grouped from 0 to 300, there are a few entries that reach 10^9. \n",
    "#These are probably errors from the turnstiles\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df_series, multiple_IQR):\n",
    "    \"\"\"\n",
    "    For a series of numerical values, remove the zeros and identify the upper outliers \n",
    "    to return a mask for all outliers in series\n",
    "    \"\"\"\n",
    "    non_zeros = df_series.replace(0, None)\n",
    "    \n",
    "    adjusted_IQR = (non_zeros.quantile(.75) - non_zeros.quantile(.25)) * multiple_IQR\n",
    "    outlier_lim = non_zeros.quantile(.75) + adjusted_IQR\n",
    "    print(outlier_lim)\n",
    "    \n",
    "    outliers = [True if x > outlier_lim else False for x in df_series]\n",
    "    \n",
    "    outlier_count = sum(outliers)\n",
    "    all_data_count = len(df_series)\n",
    "    print('{} outliers identified: {} of all data'.format(outlier_count, round(outlier_count/all_data_count,6)))\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data Len: 11014511\n",
      "Entries Outliers\n",
      "4393.0\n",
      "3061 outliers identified: 0.000278 of all data\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (12, 11011450) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-d9c8b52740e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#delete these outliers detected here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclean_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entries_outlier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n Exit Outliers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5994\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5995\u001b[0m         \"\"\"\n\u001b[1;32m-> 5996\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5997\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"copy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (12, 11011450) and data type object"
     ]
    }
   ],
   "source": [
    "#here we use 20 times the IQR as outliers, this should catch rollovers and other data artifacts\n",
    "#seems like entries of about 5,000 in a four hour period for one unit at one station is a reasonable upper limit\n",
    "print('All Data Len:', len(df))\n",
    "print('Entries Outliers')\n",
    "df['entries_outlier'] = find_outliers(df['entries_diff'], 20)\n",
    "\n",
    "#delete these outliers detected here\n",
    "clean_df = df.loc[(~df['entries_outlier'])].copy()\n",
    "\n",
    "print('\\n Exit Outliers')\n",
    "clean_df['exit_outlier'] = find_outliers(clean_df['exit_diff'], 20)\n",
    "\n",
    "\n",
    "#delete these outliers detected here\n",
    "clean_df = clean_df.loc[(~clean_df['exit_outlier'])].copy()\n",
    "\n",
    "print('Excluding Outliers Len:', len(clean_df))\n",
    "\n",
    "print('Keeping', round(len(clean_df)/len(df), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (2, 11014511) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    400\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                             \u001b[1;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[0mmax_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[0mline_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m             \u001b[0mshow_dimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_dimensions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m         )\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_string\u001b[1;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, min_rows, max_cols, show_dimensions, decimal, line_width)\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[0mshow_dimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_dimensions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m             \u001b[0mline_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    775\u001b[0m         )\n\u001b[0;32m    776\u001b[0m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, frame, buf, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, line_width, max_rows, min_rows, max_cols, show_dimensions, decimal, table_id, render_links, **kwds)\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chk_truncate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_adjustment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36m_chk_truncate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    560\u001b[0m                 \u001b[0mcol_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_cols_adj\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m                 frame = concat(\n\u001b[1;32m--> 562\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mcol_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcol_num\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m                 )\n\u001b[0;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtr_col_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1416\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   2103\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2105\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m             \u001b[1;31m# if the dim was reduced, then pass a lower-dim the next time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2137\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, obj, axis, kind)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[0;32m   3369\u001b[0m         \"\"\"\n\u001b[0;32m   3370\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3371\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3372\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1355\u001b[0m                             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m                             \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m                             \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m                         )\n\u001b[0;32m   1359\u001b[0m                     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m         new_values = algos.take_nd(\n\u001b[1;32m-> 1313\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1314\u001b[0m         )\n\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (2, 11014511) and data type float64"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (8, 11014511) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m                 \u001b[0mtable_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m                 \u001b[0mrender_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m             )\n\u001b[0;32m    702\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, frame, buf, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, line_width, max_rows, min_rows, max_cols, show_dimensions, decimal, table_id, render_links, **kwds)\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chk_truncate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_adjustment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36m_chk_truncate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    560\u001b[0m                 \u001b[0mcol_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_cols_adj\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m                 frame = concat(\n\u001b[1;32m--> 562\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mcol_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcol_num\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m                 )\n\u001b[0;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtr_col_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1416\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   2103\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2105\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m             \u001b[1;31m# if the dim was reduced, then pass a lower-dim the next time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2137\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, obj, axis, kind)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[0;32m   3369\u001b[0m         \"\"\"\n\u001b[0;32m   3370\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3371\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3372\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1355\u001b[0m                             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m                             \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m                             \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m                         )\n\u001b[0;32m   1359\u001b[0m                     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m         new_values = algos.take_nd(\n\u001b[1;32m-> 1313\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1314\u001b[0m         )\n\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (8, 11014511) and data type object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we'll delete null values from the dataset\n",
    "print('Null entry diffs', clean_df.entries_diff.isnull().sum())\n",
    "print('Null exit diffs', clean_df.exit_diff.isnull().sum())\n",
    "clean_df.dropna(subset = ['entries_diff', 'exit_diff'], how='any', inplace=True)\n",
    "print('Clean Data len:', len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report total number of data points deleted\n",
    "thrown_away = len(df) - len(clean_df)\n",
    "print(\"We're throwing away {} data points - about {} of the total\".format(thrown_away, round(thrown_away/len(df), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidate identitcal datetime columns\n",
    "clean_df = clean_df.drop(['datetime', 'date', 'time', 'group'], axis=1)\n",
    "clean_df = clean_df.rename({'datetime_clean':'datetime'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of useless columns\n",
    "clean_df = clean_df.drop(['first_row_group', 'entries_outlier', 'exit_outlier', 'entries', 'exits'], axis=1)\n",
    "clean_df = clean_df.rename({'entries_diff':'entries', 'exit_diff':'exits'} , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now sum up all the turnstiles at each subway station since thats the granularity we desire\n",
    "stations = clean_df.groupby(['station_line', 'datetime']).agg({'entries':'sum', 'exits':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-55a50ffeb4bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'station_line'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stations' is not defined"
     ]
    }
   ],
   "source": [
    "stations.groupby(['station_line', 'datetime']).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add back the other information from the original df\n",
    "stations_clean = stations.merge(clean_df[['station_line', 'datetime','station', 'linename', 'division', 'year']], how='left', copy=False, on=['station_line', 'datetime']).drop_duplicates(subset=['station_line', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations) - len(stations_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations_clean.to_pickle('Turnstile/cleaned_2014_turnstile_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad entries station_line    0.0\n",
      "datetime        0.0\n",
      "entries         0.0\n",
      "exits           0.0\n",
      "station         0.0\n",
      "linename        0.0\n",
      "division        0.0\n",
      "year            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#read back data if starting from here:\n",
    "stations_clean = pd.read_pickle('../data/Turnstile/cleaned_2015_turnstile_data.pkl')\n",
    "#we have to drop a few entries due to there  being mismatches in our data assigning turnstiles to stops \n",
    "#this amounts to less than 1% of the data though\n",
    "print('Bad entries', stations_clean.isnull().sum()/len(stations_clean))\n",
    "stations_clean = stations_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_daily = stations_clean[['station_line', 'datetime', 'entries', 'exits']].groupby(['station_line']).resample('d', on = 'datetime').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_daily_clean = stations_daily.merge(stations_clean[['station_line', 'station','linename', 'division', 'year']].drop_duplicates(), how='left', on=['station_line']).drop_duplicates(subset=['station_line', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_daily_clean.to_pickle('../data/Turnstile/2010_daily_turnstile_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983375329452313"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations_daily_clean()/len(stations_daily_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918556986826111"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations_clean.dropna())/ len(stations_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_line</th>\n",
       "      <th>datetime</th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "      <th>station</th>\n",
       "      <th>linename</th>\n",
       "      <th>division</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AVL</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>14425.0</td>\n",
       "      <td>16938.0</td>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 AVL</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>14437.0</td>\n",
       "      <td>15092.0</td>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 AVL</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>24519.0</td>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 AVL</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>22641.0</td>\n",
       "      <td>24025.0</td>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 AVL</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>23787.0</td>\n",
       "      <td>24490.0</td>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173718</th>\n",
       "      <td>ZEREGA AV6</td>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>ZEREGA AV</td>\n",
       "      <td>6</td>\n",
       "      <td>IRT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173719</th>\n",
       "      <td>ZEREGA AV6</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>2158.0</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>ZEREGA AV</td>\n",
       "      <td>6</td>\n",
       "      <td>IRT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173720</th>\n",
       "      <td>ZEREGA AV6</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>ZEREGA AV</td>\n",
       "      <td>6</td>\n",
       "      <td>IRT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173721</th>\n",
       "      <td>ZEREGA AV6</td>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>ZEREGA AV</td>\n",
       "      <td>6</td>\n",
       "      <td>IRT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173722</th>\n",
       "      <td>ZEREGA AV6</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>ZEREGA AV</td>\n",
       "      <td>6</td>\n",
       "      <td>IRT</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171539 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_line   datetime  entries    exits    station linename division  \\\n",
       "0             1 AVL 2016-01-02  14425.0  16938.0       1 AV        L      BMT   \n",
       "1             1 AVL 2016-01-03  14437.0  15092.0       1 AV        L      BMT   \n",
       "2             1 AVL 2016-01-04  21800.0  24519.0       1 AV        L      BMT   \n",
       "3             1 AVL 2016-01-05  22641.0  24025.0       1 AV        L      BMT   \n",
       "4             1 AVL 2016-01-06  23787.0  24490.0       1 AV        L      BMT   \n",
       "...             ...        ...      ...      ...        ...      ...      ...   \n",
       "173718   ZEREGA AV6 2016-12-26   1200.0   1041.0  ZEREGA AV        6      IRT   \n",
       "173719   ZEREGA AV6 2016-12-27   2158.0   1895.0  ZEREGA AV        6      IRT   \n",
       "173720   ZEREGA AV6 2016-12-28   2255.0   2134.0  ZEREGA AV        6      IRT   \n",
       "173721   ZEREGA AV6 2016-12-29   2179.0   1974.0  ZEREGA AV        6      IRT   \n",
       "173722   ZEREGA AV6 2016-12-30   2159.0   1875.0  ZEREGA AV        6      IRT   \n",
       "\n",
       "        year  \n",
       "0       2016  \n",
       "1       2016  \n",
       "2       2016  \n",
       "3       2016  \n",
       "4       2016  \n",
       "...      ...  \n",
       "173718  2016  \n",
       "173719  2016  \n",
       "173720  2016  \n",
       "173721  2016  \n",
       "173722  2016  \n",
       "\n",
       "[171539 rows x 8 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_daily.merge(stations_clean[['station_line', 'station','linename', 'division', 'year']].drop_duplicates(), how='left', on='station_line').drop_duplicates(subset=['station_line', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_clean = pd.read_pickle('../data/Turnstile/cleaned_2017_turnstile_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_clean.station.str.contains('CYPRUS HILLS').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_line</th>\n",
       "      <th>datetime</th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "      <th>station</th>\n",
       "      <th>linename</th>\n",
       "      <th>division</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3246177</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2016-12-31 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246194</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2016-12-31 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246211</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2016-12-31 12:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246228</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2016-12-31 16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246245</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2016-12-31 20:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283397</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2017-12-29 04:00:00</td>\n",
       "      <td>235.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283414</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2017-12-29 08:00:00</td>\n",
       "      <td>816.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283431</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2017-12-29 12:00:00</td>\n",
       "      <td>4135.0</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283448</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2017-12-29 16:00:00</td>\n",
       "      <td>6546.0</td>\n",
       "      <td>4056.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283465</th>\n",
       "      <td>72 ST-2 AVEQ</td>\n",
       "      <td>2017-12-29 20:00:00</td>\n",
       "      <td>3866.0</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>72 ST-2 AVE</td>\n",
       "      <td>Q</td>\n",
       "      <td>IND</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2217 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_line            datetime  entries   exits      station  \\\n",
       "3246177  72 ST-2 AVEQ 2016-12-31 04:00:00      0.0     0.0  72 ST-2 AVE   \n",
       "3246194  72 ST-2 AVEQ 2016-12-31 08:00:00      0.0     0.0  72 ST-2 AVE   \n",
       "3246211  72 ST-2 AVEQ 2016-12-31 12:00:00      2.0     1.0  72 ST-2 AVE   \n",
       "3246228  72 ST-2 AVEQ 2016-12-31 16:00:00      0.0     0.0  72 ST-2 AVE   \n",
       "3246245  72 ST-2 AVEQ 2016-12-31 20:00:00      1.0     0.0  72 ST-2 AVE   \n",
       "...               ...                 ...      ...     ...          ...   \n",
       "3283397  72 ST-2 AVEQ 2017-12-29 04:00:00    235.0   259.0  72 ST-2 AVE   \n",
       "3283414  72 ST-2 AVEQ 2017-12-29 08:00:00    816.0  2721.0  72 ST-2 AVE   \n",
       "3283431  72 ST-2 AVEQ 2017-12-29 12:00:00   4135.0  5783.0  72 ST-2 AVE   \n",
       "3283448  72 ST-2 AVEQ 2017-12-29 16:00:00   6546.0  4056.0  72 ST-2 AVE   \n",
       "3283465  72 ST-2 AVEQ 2017-12-29 20:00:00   3866.0  3391.0  72 ST-2 AVE   \n",
       "\n",
       "        linename division  year  \n",
       "3246177        Q      IND  2016  \n",
       "3246194        Q      IND  2016  \n",
       "3246211        Q      IND  2016  \n",
       "3246228        Q      IND  2016  \n",
       "3246245        Q      IND  2016  \n",
       "...          ...      ...   ...  \n",
       "3283397        Q      IND  2017  \n",
       "3283414        Q      IND  2017  \n",
       "3283431        Q      IND  2017  \n",
       "3283448        Q      IND  2017  \n",
       "3283465        Q      IND  2017  \n",
       "\n",
       "[2217 rows x 8 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_clean[(stations_clean.station == '72 ST-2 AVE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
